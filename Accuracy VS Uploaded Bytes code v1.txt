import numpy as np
import torch
import torch.nn as nn
import copy
import random
import matplotlib.pyplot as plt

# -------------------------
# Reproducibility
# -------------------------
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)

# -------------------------
# Simulation parameters
# -------------------------
num_legal = 1000
num_malicious = 2000
num_clients = num_legal + num_malicious
num_rounds = 5
feature_dim = 20
samples_per_client = 200   # stronger gradient signal
val_samples = 200
lr_local = 0.05

# Noise and stochasticity
channel_drop_prob = 0.1    # moderate
local_noise_std = 0.05     # low noise
partial_participation = 0.8

# Malicious behavior
malicious_attack_prob = 0.8
malicious_strength_min = 2.0
malicious_strength_max = 5.0

# BCE filtering threshold for SACDAFL
bce_filter_threshold = 2  # allow early updates

# -------------------------
# IP lists
# -------------------------
legal_ips = [f"192.168.0.{i}" for i in range(1, num_legal+1)]
malicious_ips = [f"10.0.0.{i}" for i in range(1, num_malicious+1)]
client_ips = legal_ips + malicious_ips

# -------------------------
# Client datasets
# -------------------------
def make_client_data(n_samples):
    X0 = np.random.normal(loc=0.0, scale=0.8, size=(n_samples//2, feature_dim))
    y0 = np.zeros((n_samples//2,))
    X1 = np.random.normal(loc=5.0, scale=0.8, size=(n_samples - n_samples//2, feature_dim))
    y1 = np.ones((n_samples - n_samples//2,))
    X = np.vstack([X0, X1])
    y = np.concatenate([y0, y1])
    idx = np.arange(len(y))
    np.random.shuffle(idx)
    return torch.tensor(X[idx], dtype=torch.float32), torch.tensor(y[idx], dtype=torch.float32).unsqueeze(1)

clients_data = [make_client_data(samples_per_client) for _ in range(num_clients)]

# -------------------------
# Validation set
# -------------------------
X_val = np.vstack([
    np.random.normal(0.0, 0.8, (val_samples//2, feature_dim)),
    np.random.normal(5.0, 0.8, (val_samples//2, feature_dim))
])
y_val = np.concatenate([np.zeros(val_samples//2), np.ones(val_samples//2)])
perm = np.arange(val_samples)
np.random.shuffle(perm)
X_val = torch.tensor(X_val[perm], dtype=torch.float32)
y_val = torch.tensor(y_val[perm], dtype=torch.float32).unsqueeze(1)

# -------------------------
# State helpers
# -------------------------
def vec_to_state(w, b):
    return {"block1": {"weight": w.clone(), "bias": b.clone()}}

def state_to_vec(state):
    return state["block1"]["weight"].clone(), state["block1"]["bias"].clone()

init_w = torch.randn(feature_dim) * 0.1  # small random init
init_b = torch.randn(1) * 0.1

def encrypt_message(key, blob): return blob
def decrypt_message(key, blob): return blob

# -------------------------
# Client local update
# -------------------------
def client_local_update(global_w, global_b, client_idx, malicious=False):
    if random.random() < channel_drop_prob:
        return None, None
    X, y = clients_data[client_idx]
    w = global_w.clone().detach().requires_grad_(True)
    b = global_b.clone().detach().requires_grad_(True)
    logits = X @ w.unsqueeze(1) + b
    loss = nn.BCEWithLogitsLoss()(logits, y)
    loss.backward()
    grad_w = w.grad.detach()
    grad_b = b.grad.detach()

    delta_w = -lr_local * grad_w + torch.randn_like(w) * local_noise_std
    delta_b = -lr_local * grad_b + torch.randn_like(b) * local_noise_std

    if malicious and random.random() < malicious_attack_prob:
        strength = random.uniform(malicious_strength_min, malicious_strength_max)
        delta_w = strength * lr_local * grad_w + torch.randn_like(w) * local_noise_std * 0.5
        delta_b = strength * lr_local * grad_b + torch.randn_like(b) * local_noise_std * 0.5

    new_w = (global_w + delta_w).detach()
    new_b = (global_b + delta_b).detach()
    state = vec_to_state(new_w, new_b)
    blob = encrypt_message(None, state)
    return blob, state

# -------------------------
# Aggregators
# -------------------------
class BaseAggregator:
    def __init__(self, name):
        self.name = name
        self.metrics = {}
        self.bytes_history = []

    @staticmethod
    def _avg_states(states):
        w_sum = sum(state_to_vec(s)[0] for s in states)
        b_sum = sum(state_to_vec(s)[1] for s in states)
        n = len(states)
        return vec_to_state(w_sum/n, b_sum/n)

class FedAvgAggregator(BaseAggregator):
    def __init__(self): super().__init__("SACFL")
    def aggregate(self, states):
        if len(states)==0: return vec_to_state(init_w, init_b)
        avg = BaseAggregator._avg_states(states)
        bytes_up = sum(state_to_vec(s)[0].numel() + state_to_vec(s)[1].numel() for s in states)
        self.metrics = {"bytes_upload": int(bytes_up), "num_clients": len(states)}
        self.bytes_history.append(bytes_up)
        return avg

class SecureAggregationAggregator(FedAvgAggregator):
    def __init__(self, overhead=1.15):
        super().__init__(); self.name="SACSAFL"; self.overhead=overhead
    def aggregate(self, states):
        avg = super().aggregate(states)
        self.bytes_history[-1] *= self.overhead
        return avg

class HomomorphicEncryptionAggregator(FedAvgAggregator):
    def __init__(self, expansion=2.8):
        super().__init__(); self.name="SACHEFL"; self.expansion=expansion
    def aggregate(self, states):
        avg = super().aggregate(states)
        self.bytes_history[-1] *= self.expansion
        return avg

class FedProxAggregator(BaseAggregator):
    def __init__(self, mu=0.0): super().__init__("SACDAFL"); self.mu=mu
    def aggregate(self, blobs, ips):
        safe_states=[]
        total_bytes=0
        for s, ip in zip(blobs, ips):
            if s is None or ip not in legal_ips: continue
            w,b = state_to_vec(s)
            total_bytes += w.numel()+b.numel()
            logits = X_val @ w.unsqueeze(1)+b
            val_loss = nn.BCEWithLogitsLoss()(logits, y_val)
            if val_loss.item() > bce_filter_threshold: continue
            safe_states.append(s)
        if len(safe_states)==0: safe_states=[vec_to_state(init_w, init_b)]
        avg = BaseAggregator._avg_states(safe_states)
        if self.mu != 0:
            w,b = state_to_vec(avg)
            avg = vec_to_state(w*(1-self.mu), b*(1-self.mu))
        self.bytes_history.append(total_bytes)
        return avg

# -------------------------
# Evaluate accuracy
# -------------------------
def eval_state(state):
    w,b = state_to_vec(state)
    logits = X_val @ w.unsqueeze(1) + b
    preds = torch.sigmoid(logits) >= 0.5
    return (preds.float() == y_val).float().mean().item()

# -------------------------
# Initialize aggregators & global states
# -------------------------
global_states = {k: vec_to_state(init_w, init_b) for k in ["SACFL","SACDAFL","SACSAFL","SACHEFL"]}
sacfl = FedAvgAggregator()
sacdafl = FedProxAggregator()
sachsa = SecureAggregationAggregator()
sachefl = HomomorphicEncryptionAggregator()
aggregators = {"SACFL":sacfl,"SACDAFL":sacdafl,"SACSAFL":sachsa,"SACHEFL":sachefl}
accuracies = {k: [] for k in aggregators.keys()}
bytes_hist = {k: [] for k in aggregators.keys()}

# -------------------------
# Federated rounds
# -------------------------
print("=== Federated rounds start ===")
for r in range(1,num_rounds+1):
    # select participants
    participants = random.sample(range(num_clients), max(2,int(partial_participation*num_clients)))

    blobs_baselines = {"SACFL": [], "SACSAFL": [], "SACHEFL": []}
    states_baselines = {"SACFL": [], "SACSAFL": [], "SACHEFL": []}
    ips_baselines = {"SACFL": [], "SACSAFL": [], "SACHEFL": []}

    for baseline in ["SACFL","SACSAFL","SACHEFL"]:
        for i in participants:
            is_mal = (i >= num_legal)
            blob,state = client_local_update(
                state_to_vec(global_states[baseline])[0],
                state_to_vec(global_states[baseline])[1],
                i, malicious=is_mal
            )
            blobs_baselines[baseline].append(blob)
            ips_baselines[baseline].append(client_ips[i])
            if state: states_baselines[baseline].append(state)

    # Aggregations
    global_states["SACFL"] = sacfl.aggregate(states_baselines["SACFL"])
    accuracies["SACFL"].append(eval_state(global_states["SACFL"]))
    bytes_hist["SACFL"].append(sacfl.bytes_history[-1])

    global_states["SACSAFL"] = sachsa.aggregate(states_baselines["SACSAFL"])
    accuracies["SACSAFL"].append(eval_state(global_states["SACSAFL"]))
    bytes_hist["SACSAFL"].append(sachsa.bytes_history[-1])

    global_states["SACHEFL"] = sachefl.aggregate(states_baselines["SACHEFL"])
    accuracies["SACHEFL"].append(eval_state(global_states["SACHEFL"]))
    bytes_hist["SACHEFL"].append(sachefl.bytes_history[-1])

    global_states["SACDAFL"] = sacdafl.aggregate(blobs_baselines["SACFL"], ips_baselines["SACFL"])
    accuracies["SACDAFL"].append(eval_state(global_states["SACDAFL"]))
    bytes_hist["SACDAFL"].append(sacdafl.bytes_history[-1])

    # Print accuracies separately
    print(f"\nRound {r}: participants={len(participants)}")
    for k in aggregators.keys():
        print(f" {k}: acc={accuracies[k][-1]:.3f}, bytes={bytes_hist[k][-1]}, clients_used={aggregators[k].metrics.get('num_clients',None)}")

print("=== Federated rounds end ===")

# -------------------------
# Plot accuracy and bytes
# -------------------------
rounds = list(range(1, num_rounds+1))
plt.figure(figsize=(10, 6))

# Plot accuracies in percentage
#for k in accuracies.keys():
    #plt.plot(rounds, [a * 100 for a in accuracies[k]], marker='o', label=k)

# Labels and formatting
#plt.xlabel("Rounds", fontsize=18)
#plt.ylabel("Accuracy (%)", fontsize=20)
#plt.ylim(0, 105)
#plt.xticks(fontsize=18)
#plt.yticks(fontsize=18)

# Legend on top

rounds = list(range(0, num_rounds+1))  # include round 0
fig, ax = plt.subplots(figsize=(10, 6))

# Plot accuracies in percentage (prepend 0 so lengths match)
for k in accuracies.keys():
    ax.plot(rounds, [0] + [a * 100 for a in accuracies[k]], marker='o', label=k)

# Labels and formatting
ax.set_xlabel("Rounds", fontsize=18, fontweight='bold')
ax.set_ylabel("Accuracy (%)", fontsize=20, fontweight='bold')
ax.set_ylim(0, 105)
ax.tick_params(axis='x', labelsize=18)
ax.tick_params(axis='y', labelsize=18)
ax.grid(True, linestyle="--", alpha=0.6)

# Legend as title bar (on top of figure)
fig.legend(
    [k for k in accuracies.keys()],
    loc="upper center",
    ncol=4,
    prop={'size': 14, 'weight': 'bold'},
    frameon=False
)

plt.tight_layout(rect=[0, 0, 1, 0.92])  # leave space on top for legend
plt.show()

#plt.subplot(1,2,2)
rounds = list(range(0, num_rounds+1))  # include round 0
fig, ax = plt.subplots(figsize=(10, 6))

# Plot bytes uploaded (prepend 0 so lengths match)
for k in bytes_hist.keys():
    ax.plot(rounds, [0] + bytes_hist[k], marker='o', label=k)

# Labels and formatting
ax.set_xlabel("Rounds", fontsize=18, fontweight='bold')
ax.set_ylabel("Bytes Uploaded", fontsize=20, fontweight='bold')
ax.tick_params(axis='x', labelsize=18)
ax.tick_params(axis='y', labelsize=18)
#ax.grid(True, linestyle="--", alpha=0.6)

# Legend as title bar (on top of figure)
fig.legend(
    [k for k in bytes_hist.keys()],
    loc="upper center",
    ncol=4,
    prop={'size': 14, 'weight': 'bold'},
    frameon=False
)

plt.tight_layout(rect=[0, 0, 1, 0.92])  # leave space for legend
plt.show()
